{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'r:\\\\Real_time_route_optimization'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "os.chdir(\"../\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.ensemble import (\n",
    "    AdaBoostRegressor,\n",
    "    GradientBoostingRegressor,\n",
    "    RandomForestRegressor,\n",
    ")\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_object(file_path, obj):\n",
    "    dir_path = os.path.dirname(file_path)\n",
    "\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "    with open(file_path, \"wb\") as file_obj:\n",
    "        pickle.dump(obj, file_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(X_train, y_train,X_test,y_test,models,param):\n",
    "        report = {}\n",
    "\n",
    "        for i in range(len(list(models))):\n",
    "            model = list(models.values())[i]\n",
    "            para=param[list(models.keys())[i]]\n",
    "\n",
    "            gs = GridSearchCV(model,para,cv=3)\n",
    "            gs.fit(X_train,y_train)\n",
    "\n",
    "            model.set_params(**gs.best_params_)\n",
    "            model.fit(X_train,y_train)\n",
    "\n",
    "            #model.fit(X_train, y_train)  # Train model\n",
    "\n",
    "            y_train_pred = model.predict(X_train)\n",
    "\n",
    "            y_test_pred = model.predict(X_test)\n",
    "\n",
    "            train_model_score = r2_score(y_train, y_train_pred)\n",
    "\n",
    "            test_model_score = r2_score(y_test, y_test_pred)\n",
    "\n",
    "            report[list(models.keys())[i]] = test_model_score\n",
    "\n",
    "        return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_arr = pd.read_csv(\"train_arr.csv\")\n",
    "test_arr = pd.read_csv(\"test_arr.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [33247, 8312]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 56\u001b[0m\n\u001b[0;32m      9\u001b[0m models \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRandom Forest\u001b[39m\u001b[38;5;124m\"\u001b[39m: RandomForestRegressor(),\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDecision Tree\u001b[39m\u001b[38;5;124m\"\u001b[39m: DecisionTreeRegressor(),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAdaBoost Regressor\u001b[39m\u001b[38;5;124m\"\u001b[39m: AdaBoostRegressor(),\n\u001b[0;32m     17\u001b[0m }\n\u001b[0;32m     18\u001b[0m params\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDecision Tree\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[0;32m     20\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcriterion\u001b[39m\u001b[38;5;124m'\u001b[39m:[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msquared_error\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfriedman_mse\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mabsolute_error\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpoisson\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \n\u001b[0;32m     54\u001b[0m }\n\u001b[1;32m---> 56\u001b[0m model_report:\u001b[38;5;28mdict\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[43mevaluate_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mX_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\u001b[43mparam\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m## To get best model score from dict\u001b[39;00m\n\u001b[0;32m     60\u001b[0m best_model_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28msorted\u001b[39m(model_report\u001b[38;5;241m.\u001b[39mvalues()))\n",
      "Cell \u001b[1;32mIn[4], line 9\u001b[0m, in \u001b[0;36mevaluate_models\u001b[1;34m(X_train, y_train, X_test, y_test, models, param)\u001b[0m\n\u001b[0;32m      6\u001b[0m para\u001b[38;5;241m=\u001b[39mparam[\u001b[38;5;28mlist\u001b[39m(models\u001b[38;5;241m.\u001b[39mkeys())[i]]\n\u001b[0;32m      8\u001b[0m gs \u001b[38;5;241m=\u001b[39m GridSearchCV(model,para,cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m \u001b[43mgs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m model\u001b[38;5;241m.\u001b[39mset_params(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mgs\u001b[38;5;241m.\u001b[39mbest_params_)\n\u001b[0;32m     12\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train,y_train)\n",
      "File \u001b[1;32mc:\\Users\\rahul\\anaconda3\\envs\\.venv\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rahul\\anaconda3\\envs\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:928\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    925\u001b[0m estimator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator\n\u001b[0;32m    926\u001b[0m scorers, refit_metric \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_scorers()\n\u001b[1;32m--> 928\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[43mindexable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    929\u001b[0m params \u001b[38;5;241m=\u001b[39m _check_method_params(X, params\u001b[38;5;241m=\u001b[39mparams)\n\u001b[0;32m    931\u001b[0m routed_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_routed_params_for_fit(params)\n",
      "File \u001b[1;32mc:\\Users\\rahul\\anaconda3\\envs\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:532\u001b[0m, in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    502\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[0;32m    503\u001b[0m \n\u001b[0;32m    504\u001b[0m \u001b[38;5;124;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;124;03m[[1, 2, 3], array([2, 3, 4]), None, <...Sparse...dtype 'int64'...shape (3, 1)>]\u001b[39;00m\n\u001b[0;32m    529\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    531\u001b[0m result \u001b[38;5;241m=\u001b[39m [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[1;32m--> 532\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    533\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\rahul\\anaconda3\\envs\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:475\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    473\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 475\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    476\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    477\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    478\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [33247, 8312]"
     ]
    }
   ],
   "source": [
    "train_array = train_arr.values()\n",
    "test_array = test_arr.values()\n",
    "\n",
    "X_train,y_train,X_test,y_test=(\n",
    "                train_array[:,:-1],\n",
    "                train_array[:,-1],\n",
    "                test_array[:,:-1],\n",
    "                test_array[:,-1]\n",
    "            )\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestRegressor(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(),\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"XGBRegressor\": XGBRegressor(),\n",
    "    \"CatBoosting Regressor\": CatBoostRegressor(verbose=False),\n",
    "    \"AdaBoost Regressor\": AdaBoostRegressor(),\n",
    "}\n",
    "params={\n",
    "    \"Decision Tree\": {\n",
    "        'criterion':['squared_error', 'friedman_mse', 'absolute_error', 'poisson'],\n",
    "        # 'splitter':['best','random'],\n",
    "        # 'max_features':['sqrt','log2'],\n",
    "    },\n",
    "    \"Random Forest\":{\n",
    "        # 'criterion':['squared_error', 'friedman_mse', 'absolute_error', 'poisson'],\n",
    "        \n",
    "        # 'max_features':['sqrt','log2',None],\n",
    "        'n_estimators': [8,16,32,64,128,256]\n",
    "    },\n",
    "    \"Gradient Boosting\":{\n",
    "        # 'loss':['squared_error', 'huber', 'absolute_error', 'quantile'],\n",
    "        'learning_rate':[.1,.01,.05,.001],\n",
    "        'subsample':[0.6,0.7,0.75,0.8,0.85,0.9],\n",
    "        # 'criterion':['squared_error', 'friedman_mse'],\n",
    "        # 'max_features':['auto','sqrt','log2'],\n",
    "        'n_estimators': [8,16,32,64,128,256]\n",
    "    },\n",
    "    \"Linear Regression\":{},\n",
    "    \"XGBRegressor\":{\n",
    "        'learning_rate':[.1,.01,.05,.001],\n",
    "        'n_estimators': [8,16,32,64,128,256]\n",
    "    },\n",
    "    \"CatBoosting Regressor\":{\n",
    "        'depth': [6,8,10],\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'iterations': [30, 50, 100]\n",
    "    },\n",
    "    \"AdaBoost Regressor\":{\n",
    "        'learning_rate':[.1,.01,0.5,.001],\n",
    "        # 'loss':['linear','square','exponential'],\n",
    "        'n_estimators': [8,16,32,64,128,256]\n",
    "    }\n",
    "    \n",
    "}\n",
    "\n",
    "model_report:dict=evaluate_models(X_train=X_train,y_train=y_train,X_test=X_test,y_test=y_test,\n",
    "                                    models=models,param=params)\n",
    "\n",
    "## To get best model score from dict\n",
    "best_model_score = max(sorted(model_report.values()))\n",
    "\n",
    "## To get best model name from dict\n",
    "\n",
    "best_model_name = list(model_report.keys())[\n",
    "    list(model_report.values()).index(best_model_score)\n",
    "]\n",
    "best_model = models[best_model_name]\n",
    "\n",
    "if best_model_score<0.6:\n",
    "\n",
    "    save_object(\n",
    "        file_path=\"artifacts/best_model.pkl\",\n",
    "        obj=best_model\n",
    "    )\n",
    "\n",
    "predicted=best_model.predict(X_test)\n",
    "\n",
    "r2_square = r2_score(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
